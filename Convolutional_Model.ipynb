{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3daa6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "######\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c68f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 70, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "model = CNN()\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 70, 70)\n",
    "\n",
    "output = model.forward(input_tensor)\n",
    "print(np.array(input_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fa1c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(img_folder, new_folder):\n",
    "    \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        \n",
    "        if dir1 != '.DS_Store':\n",
    "            \n",
    "            for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "                \n",
    "                new_name = os.path.splitext(file)\n",
    "                \n",
    "                \n",
    "                image_path = os.path.join(img_folder, dir1)\n",
    "                new_image_path = os.path.join(new_folder, dir1)\n",
    "\n",
    "                im1 = Image.open('{}/{}'.format(image_path, file))\n",
    "\n",
    "                rbg_im1 = im1.convert('RGB')\n",
    "\n",
    "\n",
    "                rbg_im1.save('{}/{}.jpg'.format(new_image_path, new_name[0]))\n",
    "                \n",
    "    return 0\n",
    "\n",
    "# create_images('fixed_images', 'new_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fce0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        if dir1 != '.DS_Store':\n",
    "            for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "                \n",
    "                \n",
    "       \n",
    "                image_path= os.path.join(img_folder, dir1,  file)\n",
    "                image= cv2.imread( image_path, 1)\n",
    "#                 image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "                image=cv2.resize(image, (100, 100),interpolation = cv2.INTER_AREA)\n",
    "                image=np.array(image)\n",
    "                image = image.astype('float32')\n",
    "                image /= 255 \n",
    "                img_data_array.append(image)\n",
    "                class_name.append(dir1)\n",
    "                \n",
    "    return img_data_array, class_name# extract the image array and class name\n",
    "'''  temp  |  lytic   '''\n",
    "\n",
    "dataset_X, dataset_y = create_dataset('new_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88836e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_X = np.array(dataset_X)\n",
    "dataset_y = np.array(dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d35ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_folder = 'fixed_images'\n",
    "# img_data_array, class_name = create_dataset(img_folder)\n",
    "\n",
    "# label_dict = {'temperate': 0, 'lytic': 1}\n",
    "# class_labels = [label_dict[label] for label in class_name]\n",
    "\n",
    "# class_labels_one_hot = to_categorical(class_labels)\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(img_data_array, class_labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(2, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(np.array(X_train), np.array(y_train), batch_size=22, epochs=100, verbose=0, validation_split=0.2)\n",
    "\n",
    "# loss, accuracy = model.evaluate(np.array(X_test), np.array(y_test), verbose=1)\n",
    "# print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "# model.save('temperate_lytic_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e72b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: sRGB: gamma value does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.6874 - accuracy: 0.5681 - val_loss: 0.6792 - val_accuracy: 0.5846\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5707 - val_loss: 0.6810 - val_accuracy: 0.5846\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5707 - val_loss: 0.6886 - val_accuracy: 0.5846\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6742 - accuracy: 0.5707 - val_loss: 0.6810 - val_accuracy: 0.5846\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5707 - val_loss: 0.6824 - val_accuracy: 0.5846\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5707 - val_loss: 0.6802 - val_accuracy: 0.5846\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5707 - val_loss: 0.6799 - val_accuracy: 0.5846\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6792 - val_accuracy: 0.5846\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6835 - accuracy: 0.5707 - val_loss: 0.6790 - val_accuracy: 0.5846\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.5707 - val_loss: 0.6793 - val_accuracy: 0.5846\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6792 - val_accuracy: 0.5846\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6789 - val_accuracy: 0.5846\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5707 - val_loss: 0.6844 - val_accuracy: 0.5846\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5707 - val_loss: 0.6778 - val_accuracy: 0.5846\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.5707 - val_loss: 0.6836 - val_accuracy: 0.5846\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5707 - val_loss: 0.6813 - val_accuracy: 0.5846\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5707 - val_loss: 0.6884 - val_accuracy: 0.5846\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5707 - val_loss: 0.6804 - val_accuracy: 0.5846\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.5707 - val_loss: 0.6791 - val_accuracy: 0.5846\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5707 - val_loss: 0.6795 - val_accuracy: 0.5846\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6792 - val_accuracy: 0.5846\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6795 - val_accuracy: 0.5846\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5707 - val_loss: 0.6762 - val_accuracy: 0.5846\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5707 - val_loss: 0.6806 - val_accuracy: 0.5846\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6802 - accuracy: 0.5707 - val_loss: 0.6779 - val_accuracy: 0.5846\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6782 - accuracy: 0.5707 - val_loss: 0.6796 - val_accuracy: 0.5846\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5707 - val_loss: 0.6796 - val_accuracy: 0.5846\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5707 - val_loss: 0.6801 - val_accuracy: 0.5846\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6746 - accuracy: 0.5707 - val_loss: 0.6813 - val_accuracy: 0.5846\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6712 - accuracy: 0.5707 - val_loss: 0.6800 - val_accuracy: 0.5846\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6680 - accuracy: 0.5707 - val_loss: 0.6811 - val_accuracy: 0.5846\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6770 - accuracy: 0.5707 - val_loss: 0.6797 - val_accuracy: 0.5846\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5707 - val_loss: 0.6807 - val_accuracy: 0.5846\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6786 - accuracy: 0.5707 - val_loss: 0.6811 - val_accuracy: 0.5846\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6750 - accuracy: 0.5707 - val_loss: 0.7024 - val_accuracy: 0.5846\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6661 - accuracy: 0.5707 - val_loss: 0.6951 - val_accuracy: 0.5846\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6653 - accuracy: 0.5707 - val_loss: 0.7398 - val_accuracy: 0.5846\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6711 - accuracy: 0.5707 - val_loss: 0.6825 - val_accuracy: 0.5846\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.5707 - val_loss: 0.7145 - val_accuracy: 0.5846\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6636 - accuracy: 0.5707 - val_loss: 0.6840 - val_accuracy: 0.5846\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.6694 - accuracy: 0.5707 - val_loss: 0.7335 - val_accuracy: 0.5846\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6644 - accuracy: 0.5707 - val_loss: 0.7063 - val_accuracy: 0.5846\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6610 - accuracy: 0.5707 - val_loss: 0.6811 - val_accuracy: 0.5846\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6547 - accuracy: 0.5707 - val_loss: 0.7069 - val_accuracy: 0.5846\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6493 - accuracy: 0.5707 - val_loss: 0.7103 - val_accuracy: 0.5846\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6496 - accuracy: 0.5707 - val_loss: 0.6959 - val_accuracy: 0.5846\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6479 - accuracy: 0.5707 - val_loss: 0.6903 - val_accuracy: 0.5846\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6325 - accuracy: 0.5964 - val_loss: 0.7168 - val_accuracy: 0.4513\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6413 - accuracy: 0.5977 - val_loss: 0.7192 - val_accuracy: 0.6513\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6154 - accuracy: 0.6555 - val_loss: 0.6365 - val_accuracy: 0.6974\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6468 - accuracy: 0.5887 - val_loss: 0.7057 - val_accuracy: 0.5897\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6269 - accuracy: 0.6144 - val_loss: 0.7381 - val_accuracy: 0.5949\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6472 - accuracy: 0.6105 - val_loss: 0.6831 - val_accuracy: 0.5846\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6502 - accuracy: 0.5707 - val_loss: 0.6838 - val_accuracy: 0.5846\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6197 - accuracy: 0.6170 - val_loss: 0.7386 - val_accuracy: 0.6718\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6031 - accuracy: 0.6645 - val_loss: 0.7793 - val_accuracy: 0.6154\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.6288 - accuracy: 0.6272 - val_loss: 0.7203 - val_accuracy: 0.6154\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 12ms/step - loss: 0.6039 - accuracy: 0.6350 - val_loss: 0.8729 - val_accuracy: 0.6103\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5326 - accuracy: 0.7301 - val_loss: 0.8046 - val_accuracy: 0.6872\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4574 - accuracy: 0.7828 - val_loss: 0.5380 - val_accuracy: 0.7795\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.4583 - accuracy: 0.7853 - val_loss: 0.7091 - val_accuracy: 0.7282\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.6144 - accuracy: 0.6350 - val_loss: 0.7276 - val_accuracy: 0.6103\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5822 - accuracy: 0.6748 - val_loss: 0.8100 - val_accuracy: 0.4667\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5184 - accuracy: 0.7249 - val_loss: 0.9137 - val_accuracy: 0.6256\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.4838 - accuracy: 0.7558 - val_loss: 0.9446 - val_accuracy: 0.6974\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.4030 - accuracy: 0.8226 - val_loss: 0.7961 - val_accuracy: 0.7692\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3837 - accuracy: 0.8213 - val_loss: 1.0496 - val_accuracy: 0.7692\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.4147 - accuracy: 0.8162 - val_loss: 1.1829 - val_accuracy: 0.7487\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3381 - accuracy: 0.8445 - val_loss: 1.0760 - val_accuracy: 0.7128\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3262 - accuracy: 0.8702 - val_loss: 0.9760 - val_accuracy: 0.7692\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.2693 - accuracy: 0.8766 - val_loss: 1.1074 - val_accuracy: 0.7897\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2708 - accuracy: 0.8830 - val_loss: 1.5258 - val_accuracy: 0.7436\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3325 - accuracy: 0.8586 - val_loss: 1.1364 - val_accuracy: 0.7385\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2484 - accuracy: 0.8972 - val_loss: 0.8016 - val_accuracy: 0.7641\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1964 - accuracy: 0.9267 - val_loss: 1.5941 - val_accuracy: 0.7795\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1900 - accuracy: 0.9242 - val_loss: 1.2613 - val_accuracy: 0.7949\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.9370 - val_loss: 1.3622 - val_accuracy: 0.7744\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1623 - accuracy: 0.9396 - val_loss: 2.6496 - val_accuracy: 0.7487\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2282 - accuracy: 0.8985 - val_loss: 1.5428 - val_accuracy: 0.7590\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1817 - accuracy: 0.9229 - val_loss: 1.6941 - val_accuracy: 0.7744\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1215 - accuracy: 0.9550 - val_loss: 1.9265 - val_accuracy: 0.7538\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1569 - accuracy: 0.9460 - val_loss: 2.2008 - val_accuracy: 0.6923\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2230 - accuracy: 0.9049 - val_loss: 1.5488 - val_accuracy: 0.7641\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1483 - accuracy: 0.9499 - val_loss: 2.1260 - val_accuracy: 0.7590\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1982 - accuracy: 0.9242 - val_loss: 2.1143 - val_accuracy: 0.6718\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1895 - accuracy: 0.9319 - val_loss: 1.8290 - val_accuracy: 0.7744\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1508 - accuracy: 0.9473 - val_loss: 1.7939 - val_accuracy: 0.7538\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0846 - accuracy: 0.9640 - val_loss: 2.5161 - val_accuracy: 0.7282\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0854 - accuracy: 0.9627 - val_loss: 3.3360 - val_accuracy: 0.7385\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1522 - accuracy: 0.9460 - val_loss: 1.9851 - val_accuracy: 0.7282\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0884 - accuracy: 0.9653 - val_loss: 2.7649 - val_accuracy: 0.7231\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0542 - accuracy: 0.9781 - val_loss: 2.8072 - val_accuracy: 0.7231\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0400 - accuracy: 0.9884 - val_loss: 3.6792 - val_accuracy: 0.7538\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9961 - val_loss: 3.9716 - val_accuracy: 0.7487\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 3.4398 - val_accuracy: 0.7590\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0724 - accuracy: 0.9769 - val_loss: 2.6882 - val_accuracy: 0.7641\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0684 - accuracy: 0.9730 - val_loss: 2.8763 - val_accuracy: 0.7026\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0636 - accuracy: 0.9807 - val_loss: 2.7696 - val_accuracy: 0.7590\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9756 - val_loss: 2.6123 - val_accuracy: 0.6923\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1037 - accuracy: 0.9653 - val_loss: 1.8124 - val_accuracy: 0.7590\n",
      "Model before using DataGenerator:\n",
      "\n",
      "\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9679\n",
      "Training accuracy: 0.9678663015365601\n",
      "\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.8124 - accuracy: 0.7590\n",
      "Test accuracy: 0.7589743733406067\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 23ms/step - loss: 1.0184 - accuracy: 0.7042 - val_loss: 0.6375 - val_accuracy: 0.6923\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.6530 - accuracy: 0.6884 - val_loss: 0.6164 - val_accuracy: 0.7436\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.6177 - accuracy: 0.7074 - val_loss: 0.5498 - val_accuracy: 0.7692\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.5713 - accuracy: 0.7395 - val_loss: 0.4884 - val_accuracy: 0.7641\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.5045 - accuracy: 0.7663 - val_loss: 0.4533 - val_accuracy: 0.7897\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.5453 - accuracy: 0.7550 - val_loss: 0.5064 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.5514 - accuracy: 0.7411 - val_loss: 0.4856 - val_accuracy: 0.7744\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4910 - accuracy: 0.7705 - val_loss: 0.4511 - val_accuracy: 0.7897\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4944 - accuracy: 0.7682 - val_loss: 0.4560 - val_accuracy: 0.7949\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4618 - accuracy: 0.7853 - val_loss: 0.4344 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4281 - accuracy: 0.7991 - val_loss: 0.5194 - val_accuracy: 0.7897\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.5230 - accuracy: 0.7682 - val_loss: 0.4540 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4800 - accuracy: 0.7925 - val_loss: 0.4249 - val_accuracy: 0.8051\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4305 - accuracy: 0.7979 - val_loss: 0.4187 - val_accuracy: 0.7949\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.4366 - accuracy: 0.8057 - val_loss: 0.4143 - val_accuracy: 0.7949\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4638 - accuracy: 0.8057 - val_loss: 0.4752 - val_accuracy: 0.7846\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4299 - accuracy: 0.8124 - val_loss: 0.3991 - val_accuracy: 0.8154\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4808 - accuracy: 0.7853 - val_loss: 0.4204 - val_accuracy: 0.8205\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4432 - accuracy: 0.7937 - val_loss: 0.4243 - val_accuracy: 0.7795\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4579 - accuracy: 0.7874 - val_loss: 0.4343 - val_accuracy: 0.7949\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4405 - accuracy: 0.7881 - val_loss: 0.4080 - val_accuracy: 0.8103\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4431 - accuracy: 0.8105 - val_loss: 0.3977 - val_accuracy: 0.8103\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3944 - accuracy: 0.8168 - val_loss: 0.3994 - val_accuracy: 0.8051\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3967 - accuracy: 0.8411 - val_loss: 0.4000 - val_accuracy: 0.8154\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3911 - accuracy: 0.8146 - val_loss: 0.4121 - val_accuracy: 0.8308\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4070 - accuracy: 0.8300 - val_loss: 0.4887 - val_accuracy: 0.8256\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4476 - accuracy: 0.7881 - val_loss: 0.4035 - val_accuracy: 0.8051\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4316 - accuracy: 0.8124 - val_loss: 0.3986 - val_accuracy: 0.8154\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4044 - accuracy: 0.8274 - val_loss: 0.4240 - val_accuracy: 0.8205\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4220 - accuracy: 0.8147 - val_loss: 0.4133 - val_accuracy: 0.8154\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4488 - accuracy: 0.8057 - val_loss: 0.5045 - val_accuracy: 0.7590\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4811 - accuracy: 0.7837 - val_loss: 0.4370 - val_accuracy: 0.8051\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4357 - accuracy: 0.8189 - val_loss: 0.4037 - val_accuracy: 0.8154\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4383 - accuracy: 0.8042 - val_loss: 0.4384 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4157 - accuracy: 0.8124 - val_loss: 0.4417 - val_accuracy: 0.8103\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4207 - accuracy: 0.8190 - val_loss: 0.3973 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4478 - accuracy: 0.7789 - val_loss: 0.4192 - val_accuracy: 0.8154\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4013 - accuracy: 0.8168 - val_loss: 0.3923 - val_accuracy: 0.8205\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3484 - accuracy: 0.8587 - val_loss: 0.3988 - val_accuracy: 0.8205\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.4440 - accuracy: 0.7792 - val_loss: 0.4059 - val_accuracy: 0.8256\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4197 - accuracy: 0.8505 - val_loss: 0.4335 - val_accuracy: 0.8051\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3942 - accuracy: 0.8421 - val_loss: 0.3957 - val_accuracy: 0.8051\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3675 - accuracy: 0.8442 - val_loss: 0.3969 - val_accuracy: 0.8205\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4231 - accuracy: 0.8168 - val_loss: 0.4932 - val_accuracy: 0.8103\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.4235 - accuracy: 0.8146 - val_loss: 0.4293 - val_accuracy: 0.8051\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3988 - accuracy: 0.8253 - val_loss: 0.4598 - val_accuracy: 0.8051\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4057 - accuracy: 0.8316 - val_loss: 0.4266 - val_accuracy: 0.8051\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4010 - accuracy: 0.8147 - val_loss: 0.4031 - val_accuracy: 0.8205\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3956 - accuracy: 0.8411 - val_loss: 0.4013 - val_accuracy: 0.8205\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4110 - accuracy: 0.8189 - val_loss: 0.4016 - val_accuracy: 0.8205\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4045 - accuracy: 0.8168 - val_loss: 0.4141 - val_accuracy: 0.8256\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4531 - accuracy: 0.7916 - val_loss: 0.3939 - val_accuracy: 0.8308\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3799 - accuracy: 0.8411 - val_loss: 0.3887 - val_accuracy: 0.8205\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3638 - accuracy: 0.8611 - val_loss: 0.4117 - val_accuracy: 0.8103\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4405 - accuracy: 0.8013 - val_loss: 0.4282 - val_accuracy: 0.8205\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4139 - accuracy: 0.8366 - val_loss: 0.4208 - val_accuracy: 0.8205\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4345 - accuracy: 0.8079 - val_loss: 0.3852 - val_accuracy: 0.8205\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4349 - accuracy: 0.8147 - val_loss: 0.3846 - val_accuracy: 0.8308\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3502 - accuracy: 0.8547 - val_loss: 0.4122 - val_accuracy: 0.8256\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.4138 - accuracy: 0.8211 - val_loss: 0.3770 - val_accuracy: 0.8256\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3747 - accuracy: 0.8477 - val_loss: 0.3811 - val_accuracy: 0.8513\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3980 - accuracy: 0.8234 - val_loss: 0.4247 - val_accuracy: 0.8359\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3691 - accuracy: 0.8389 - val_loss: 0.3746 - val_accuracy: 0.8256\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3204 - accuracy: 0.8587 - val_loss: 0.4111 - val_accuracy: 0.8103\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3905 - accuracy: 0.8344 - val_loss: 0.3939 - val_accuracy: 0.8410\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4062 - accuracy: 0.8189 - val_loss: 0.4209 - val_accuracy: 0.8359\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.4423 - accuracy: 0.8102 - val_loss: 0.3617 - val_accuracy: 0.8256\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3968 - accuracy: 0.8366 - val_loss: 0.3713 - val_accuracy: 0.8359\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3541 - accuracy: 0.8463 - val_loss: 0.5777 - val_accuracy: 0.8000\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4184 - accuracy: 0.8105 - val_loss: 0.4025 - val_accuracy: 0.8359\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3664 - accuracy: 0.8611 - val_loss: 0.4110 - val_accuracy: 0.8308\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3915 - accuracy: 0.8344 - val_loss: 0.3728 - val_accuracy: 0.8205\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3918 - accuracy: 0.8316 - val_loss: 0.3603 - val_accuracy: 0.8462\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3466 - accuracy: 0.8526 - val_loss: 0.3520 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3632 - accuracy: 0.8484 - val_loss: 0.3730 - val_accuracy: 0.8410\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3500 - accuracy: 0.8653 - val_loss: 0.4166 - val_accuracy: 0.8410\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3427 - accuracy: 0.8609 - val_loss: 0.3670 - val_accuracy: 0.8513\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3461 - accuracy: 0.8455 - val_loss: 0.3918 - val_accuracy: 0.8462\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3315 - accuracy: 0.8587 - val_loss: 0.3542 - val_accuracy: 0.8564\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.3807 - accuracy: 0.8300 - val_loss: 0.4407 - val_accuracy: 0.8410\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4166 - accuracy: 0.8057 - val_loss: 0.3727 - val_accuracy: 0.8615\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.3188 - accuracy: 0.8786 - val_loss: 0.3756 - val_accuracy: 0.8513\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.2835 - accuracy: 0.8758 - val_loss: 0.4798 - val_accuracy: 0.8513\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4304 - accuracy: 0.8212 - val_loss: 0.5091 - val_accuracy: 0.7692\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.4169 - accuracy: 0.8105 - val_loss: 0.3929 - val_accuracy: 0.8359\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3589 - accuracy: 0.8674 - val_loss: 0.4154 - val_accuracy: 0.8308\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3730 - accuracy: 0.8463 - val_loss: 0.5137 - val_accuracy: 0.7795\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.4113 - accuracy: 0.8146 - val_loss: 0.3918 - val_accuracy: 0.8359\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3619 - accuracy: 0.8499 - val_loss: 0.3709 - val_accuracy: 0.8462\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3573 - accuracy: 0.8526 - val_loss: 0.3604 - val_accuracy: 0.8359\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3211 - accuracy: 0.8742 - val_loss: 0.3597 - val_accuracy: 0.8410\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3602 - accuracy: 0.8543 - val_loss: 0.3586 - val_accuracy: 0.8410\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3368 - accuracy: 0.8589 - val_loss: 0.4583 - val_accuracy: 0.8308\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3777 - accuracy: 0.8411 - val_loss: 0.3700 - val_accuracy: 0.8462\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3638 - accuracy: 0.8433 - val_loss: 0.3640 - val_accuracy: 0.8410\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3450 - accuracy: 0.8543 - val_loss: 0.3661 - val_accuracy: 0.8410\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3310 - accuracy: 0.8742 - val_loss: 0.4185 - val_accuracy: 0.8205\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.3606 - accuracy: 0.8609 - val_loss: 0.3621 - val_accuracy: 0.8462\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3466 - accuracy: 0.8505 - val_loss: 0.3755 - val_accuracy: 0.8410\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.3399 - accuracy: 0.8587 - val_loss: 0.3682 - val_accuracy: 0.8615\n",
      "Model with after using DataGenerator:\n",
      "\n",
      "\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.2448 - accuracy: 0.9075\n",
      "Training accuracy: 0.9074550271034241\n",
      "\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8615\n",
      "Test accuracy: 0.8615384697914124\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "\n",
    "\n",
    "img_folder = 'fixed_images'\n",
    "img_data_array, class_name = create_dataset(img_folder)\n",
    "\n",
    "label_dict = {'temperate': 0, 'lytic': 1}\n",
    "class_labels = [label_dict[label] for label in class_name]\n",
    "\n",
    "new_y = to_categorical(class_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_data_array, new_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# This code might break it, so remove in the future\n",
    "\n",
    "X_train = rgb_to_grayscale(X_train)\n",
    "X_test = rgb_to_grayscale(X_test)\n",
    "\n",
    "############################\n",
    "\n",
    "def kernelInitializer(shape, dtype=None):   \n",
    "    sobel_x = tf.constant(\n",
    "        [\n",
    "            [-5, -4, 0, 4, 5], \n",
    "            [-8, -10, 0, 10, 8], \n",
    "            [-10, -20, 0, 20, 10], \n",
    "            [-8, -10, 0, 10, 8], \n",
    "            [-5, -4, 0, 4, 5]\n",
    "        ], dtype=dtype )\n",
    "    \n",
    "    sobel_x = tf.reshape(sobel_x, (5, 5, 1, 1))\n",
    "    \n",
    "    sobel_x = tf.tile(sobel_x, (1, 1, shape[-2],shape[-1]))\n",
    "\n",
    "    print(tf.shape(sobel_x))\n",
    "    \n",
    "    return sobel_x\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Model with more layers, batch normalization, and L1/L2 regularization\n",
    "model = Sequential([\n",
    "    Conv2D(64, (5, 5), activation='relu', input_shape=(100, 100, 1), strides=(2,2)),\n",
    "#     BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', strides=(2,2)),\n",
    "#     BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "#     Conv2D(16, (3, 3), activation='relu', strides=(2,2)),\n",
    "#     BatchNormalization(),\n",
    "#     MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    \n",
    "#     Dense(256, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
    "#     Dense(232, activation='relu'),\n",
    "    Dense(216, activation='relu'),\n",
    "    Dense(200, activation='relu'),\n",
    "    Dense(180, activation='relu'),\n",
    "    Dense(150, activation='relu'),\n",
    "    Dense(125, activation='relu'),\n",
    "    Dense(90, activation='relu'),\n",
    "    Dense(75, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    \n",
    "#     Dropout(0.2),\n",
    "    \n",
    "    Dense(2, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "training_set = datagen.flow(np.array(X_train), np.array(y_train), batch_size=25)\n",
    "\n",
    "# Fit the model with data augmentation\n",
    "\n",
    "# Can use 'training_set' for overfitting, or can use X_train and y_train straight up\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=20,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test))\n",
    "          #\n",
    "         )\n",
    "\n",
    "print('Model before using DataGenerator:\\n\\n')\n",
    "loss, accuracy = model.evaluate(np.array(X_train), np.array(y_train), verbose=1)\n",
    "print(f\"Training accuracy: {accuracy}\\n\")\n",
    "loss, accuracy = model.evaluate(np.array(X_test), np.array(y_test), verbose=1)\n",
    "print(f\"Test accuracy: {accuracy}\\n\\n\")\n",
    "\n",
    "model.fit(training_set,\n",
    "          steps_per_epoch=np.array(X_train).shape[0] // 40,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test))\n",
    "          #\n",
    "         )\n",
    "\n",
    "print('Model with after using DataGenerator:\\n\\n')\n",
    "loss, accuracy = model.evaluate(np.array(X_train), np.array(y_train), verbose=1)\n",
    "print(f\"Training accuracy: {accuracy}\\n\")\n",
    "loss, accuracy = model.evaluate(np.array(X_test), np.array(y_test), verbose=1)\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "model.save('temperate_lytic_classifier_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4d4783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(973, 100, 100, 3)\n",
      "(973, 3, 100, 100)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gh/3bjl5ccn37q7d9231z21l5br0000gn/T/ipykernel_19436/4011128456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "shape = dataset_X.shape\n",
    "\n",
    "print(dataset_X.shape)\n",
    "\n",
    "dataset_X = np.reshape(dataset_X, (shape[0],shape[3],shape[1],shape[2]))\n",
    "\n",
    "print(dataset_X.shape)\n",
    "\n",
    "output = model.forward(torch.tensor(dataset_X))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcabd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.compile(CNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d707612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS IF YOU WANT TO KEEP KERNEL ALIVE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
